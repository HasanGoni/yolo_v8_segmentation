[
  {
    "objectID": "03_yolo_v8_starting.html",
    "href": "03_yolo_v8_starting.html",
    "title": "yolo_v8_segmentation",
    "section": "",
    "text": "#Detection model\ndet_model = YOLO('yolov8n.pt')\n\n#Instance model\ninst_model = YOLO('yolov8n-seg.pt')\n\n\nmodel = YOLO('yolov8n-seg.yaml') \nmodel = YOLO('yolov8n-seg.pt')\n\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1   1150432  ultralytics.nn.modules.head.Segment          [80, 32, 64, [64, 128, 256]]  \nYOLOv8n-seg summary: 261 layers, 3409968 parameters, 3409952 gradients, 12.8 GFLOPs\n\n\n\n\ndata_yaml_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/data.yaml')\n\n\nwith open (f'{data_yaml_path}') as f:\n    num_classes = yaml.safe_load(f)['nc']\n\n\nmodel.train?\n\nSignature: model.train(trainer=None, **kwargs)\nDocstring:\nTrains the model on a given dataset.\n\nArgs:\n    trainer (BaseTrainer, optional): Customized trainer.\n    **kwargs (Any): Any number of arguments representing the training configuration.\nFile:      ~/mambaforge/envs/yolo_v8/lib/python3.10/site-packages/ultralytics/engine/model.py\nType:      method\n\n\n\nproject = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/yolo_v8_training')\nname = 'Sample_training'\nresult = model.train(\n    data=str(data_yaml_path),\n    name = name,\n    epochs = 2,\n    patience = 0,\n    batch=4,\n    imgsz=256,\n\n)\n\nNew https://pypi.org/project/ultralytics/8.0.225 available üòÉ Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.222 üöÄ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10989MiB)\nengine/trainer: task=segment, mode=train, model=yolov8n-seg.pt, data=/home/hasan/Schreibtisch/projects/data/microscopy/data.yaml, epochs=2, patience=0, batch=4, imgsz=256, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=Sample_training4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/Sample_training4\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \nYOLOv8n-seg summary: 261 layers, 3263811 parameters, 3263795 gradients, 12.1 GFLOPs\n\nTransferred 381/417 items from pretrained weights\nTensorBoard: Start with 'tensorboard --logdir runs/segment/Sample_training4', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\nAMP: running Automatic Mixed Precision (AMP) checks with YOLOv8n...\nAMP: checks passed ‚úÖ\ntrain: New cache created: /home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/labels.cache\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\nWARNING ‚ö†Ô∏è No labels found in /home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\nPlotting labels to runs/segment/Sample_training4/labels.jpg... \noptimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \noptimizer: AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\nImage sizes 256 train, 256 val\nUsing 4 dataloader workers\nLogging results to runs/segment/Sample_training4\nStarting training for 2 epochs...\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n                   all       1642          0          0          0          0          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in segment set, can not compute metrics without labels\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n                   all       1642          0          0          0          0          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in segment set, can not compute metrics without labels\n\n2 epochs completed in 0.018 hours.\nOptimizer stripped from runs/segment/Sample_training4/weights/last.pt, 6.7MB\nOptimizer stripped from runs/segment/Sample_training4/weights/best.pt, 6.7MB\n\nValidating runs/segment/Sample_training4/weights/best.pt...\nUltralytics YOLOv8.0.222 üöÄ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10989MiB)\nYOLOv8n-seg summary (fused): 195 layers, 3258259 parameters, 0 gradients, 12.0 GFLOPs\n                   all       1642          0          0          0          0          0          0          0          0          0\nWARNING ‚ö†Ô∏è no labels found in segment set, can not compute metrics without labels\nSpeed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to runs/segment/Sample_training4\n\n\ntrain: Scanning /home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/labels... 1633 images, 9 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1642/1642 [00:01&lt;00:00, 1311.67it/s]\nval: Scanning /home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images.cache... 0 images, 1642 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1642/1642 [00:00&lt;?, ?it/s]\n        1/2      0.57G      1.371      1.869      1.621      1.169          8        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 411/411 [00:26&lt;00:00, 15.52it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 206/206 [00:05&lt;00:00, 37.54it/s]\n        2/2     0.621G      1.094      1.361     0.9631      1.023          7        256: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 411/411 [00:24&lt;00:00, 16.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 206/206 [00:05&lt;00:00, 37.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 206/206 [00:04&lt;00:00, 44.32it/s]\n\n\n\nimport torch\ntorch.cuda.is_available()\n\nFalse",
    "crumbs": [
      "03_yolo_v8_starting.html"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "viz_utils.html",
    "href": "viz_utils.html",
    "title": "Vizailization will be created here",
    "section": "",
    "text": "Viz notebook\n\n\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nmpl.rcParams['image.cmap'] = 'gray'\n\n\nPath.home()\n\nPath('/home/hasan')\n\n\n\nim_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/')\nmask_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/')\n#im_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_images/')\n#mask_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_masks')\n\nimages=im_path.ls()\nmasks=mask_path.ls()\n\n\nr_idx = np.random.choice(len(im_path.ls()), 1)[0]\n\n\ns_img = images[r_idx]\ns_msk = masks[r_idx]\n\n\ns_img.name, s_msk.name\n\n('img_21_p_3.png', 'img_21_p_3.png')\n\n\n\nsn_msk_img = cv2.imread(str(s_msk), cv2.IMREAD_GRAYSCALE)\nnp.unique(sn_msk_img)\n\narray([  0, 255], dtype=uint8)\n\n\n\nsource\n\noverlay_mask\n\n overlay_mask (im_path, msk_path, overlay_clr=(0, 1, 0), scale=1,\n               alpha=0.5)\n\nCreaete a overlay image from image and mask\n\noverlay_mask(s_img, s_msk,alpha=0.1)\n\n\n\n\n\n\n\n\n\nsource\n\n\noverlay_mask_border_on_image\n\n overlay_mask_border_on_image (im_path, msk_path, border_color=(0, 1, 0),\n                               border_width=1)\n\n*Overlays the border of a binary mask on a grayscale image and displays the result using matplotlib.\nArgs: image (numpy.ndarray): Grayscale image. mask (numpy.ndarray): Binary mask of the same size as the image. border_color (tuple): RGB color for the mask border in the range [0, 1]. border_width (int): Width of the border.\nReturns: None: The function displays a plot.*\n\noverlay_mask_border_on_image(s_img, s_msk)\n\n\n\n\n\n\n\n\n\n#yolo_mask_path = Path(r'/home/hasan/workspace/data/microscopy_data/yolo_dataset_train')\n#im_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_images/')\nyolo_mask_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train')\nim_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/')\nyolo_mask_path.ls(), im_path.ls()\n\n((#1633) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_139_p_11.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_48_p_0.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_120_p_1.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_54_p_9.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_2_p_2.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_34_p_10.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_50_p_1.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_42_p_8.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_67_p_1.txt'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_20_p_1.txt')...],\n (#1642) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_162_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_11_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_70_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_67_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_74_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_16_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_23_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_112_p_6.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_121_p_11.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_152_p_1.png')...])\n\n\n\nr_idx = np.random.choice(len(im_path.ls()), 1)[0]\nprint(f'random index: {r_idx}')\n\nrandom index: 546\n\n\n\nyolo_mask_path.ls()[r_idx], im_path.ls()[r_idx]\n\n(Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/img_27_p_0.txt'),\n Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_73_p_6.png'))\n\n\n\nsource\n\n\noverlay_yolo_mask\n\n overlay_yolo_mask (im_path, msk_path, color=None, idx=None, im_name=None,\n                    fill=False, alpha=0.3)\n\nCreaete a overlay image from image and mask\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nim_path\n\n\n\n\n\nmsk_path\n\n\n\n\n\ncolor\nNoneType\nNone\ncolor values other matplotlib colors\n\n\nidx\nNoneType\nNone\nIndex of image in the folder other random will be chosen\n\n\nim_name\nNoneType\nNone\nImge name with extension\n\n\nfill\nbool\nFalse\nwhther to fill the mask or not\n\n\nalpha\nfloat\n0.3\nalpha value for the mask for transparency\n\n\n\n\noverlay_yolo_mask(im_path, msk_path=yolo_mask_path, color='red', fill=False)",
    "crumbs": [
      "Vizailization will be created here"
    ]
  },
  {
    "objectID": "data_preparation.html",
    "href": "data_preparation.html",
    "title": "first find the data",
    "section": "",
    "text": "code highly taken from here\n\npath = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy')\npath.ls()\n\n(#9) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_mask_train_coco_format.json'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_mask_val_coco_format.json'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images.cache'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/train_images'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/data.yaml'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/train_msks'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train')]\n\n\n\n#trn_msk_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_images')\n#trn_img_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_masks/')\n#trn_output_path = Path(r'/home/hasan/workspace/data/microscopy_data/yolo_dataset_train')\n\ntrn_msk_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks')\ntrn_img_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images')\n\nval_msk_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_val_masks')\nval_img_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_val_images')\n\ntrn_output_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train')\nval_output_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_test')\nPath(trn_output_path).mkdir(parents=True, exist_ok=True)    \n\n#val_msk_path = Path(r'/home/hasan/workspace/data/microscopy_data/test_patch_images/')\n#val_img_path = Path(r'/home/hasan/workspace/data/microscopy_data/test_patch_masks/')\n#val_output_path = Path(r'/home/hasan/workspace/data/microscopy_data/yolo_dataset_test')\n#Path(val_output_path).mkdir(parents=True, exist_ok=True)\n\n#trn_json_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_mask_train_coco_format.json')\n#val_json_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_mask_val_coco_format.json')\n\ntrn_json_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_mask_train_coco_format.json')\nval_json_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_mask_val_coco_format.json')\ntrn_msk_path.ls(), trn_img_path.ls()\n\n((#1642) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_162_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_11_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_70_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_67_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_74_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_16_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_23_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_112_p_6.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_121_p_11.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/img_152_p_1.png')...],\n (#1642) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_162_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_11_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_70_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_67_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_74_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_16_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_23_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_112_p_6.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_121_p_11.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/img_152_p_1.png')...])\n\n\n\nWe need to create a format which can yolov8 works\n### 1. First convert coco format\n\nsource\n\nget_contours\n\n get_contours (img:numpy.ndarray)\n\nget contours from masks\n\nsource\n\n\nfrom_contr_to_annotation\n\n from_contr_to_annotation (sn_cntr:list, consider_min_area:bool=True,\n                           min_area:int=0)\n\nCreate annotation dict from a single contour\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsn_cntr\nlist\n\nsingle contour\n\n\nconsider_min_area\nbool\nTrue\nwhether to use min_area parameter\n\n\nmin_area\nint\n0\n\n\n\nReturns\ntyping.Tuple\n\n\n\n\n\n\nsource\n\n\nget_mask_info\n\n get_mask_info (msk_path, min_area=0)\n\n\nimage_infos, annotations, annotation_id=get_mask_info(trn_msk_path, min_area=0)\n\n\n\n\n\ncategory_ids = {\n    \"object\": 1,\n}\n\n\nsource\n\n\nprocess_masks\n\n process_masks (mask_path:Union[str,pathlib.Path],\n                json_path:Union[str,pathlib.Path], category_ids:Dict)\n\n\nCreating coco format json file for training set\n\nprocess_masks(\n    mask_path=trn_msk_path, \n    json_path=trn_json_path, \n    category_ids=category_ids)\n\n\n\n\n\n\nCreating coco format for validation data\n\nprocess_masks(\n    mask_path=val_msk_path, \n    json_path=val_json_path, \n    category_ids=category_ids)\n\n\n\n\n\n\n\n2. Now convet to yolo format\n\nsource\n\n\nread_json\n\n read_json (file_path)\n\n\ntrn_images = trn_img_path.ls()\n\n\njson_data = read_json(trn_json_path)\n\n\njson_data.keys()\n\ndict_keys(['annotations', 'categories', 'images', 'info', 'licenses'])\n\n\n\nsource\n\n\nget_file_info\n\n get_file_info (json_data:dict, file_name:str)\n\n\nsource\n\n\nget_annotations\n\n get_annotations (json_data:dict, file_name:str)\n\n\nsource\n\n\nnormalized_polygon\n\n normalized_polygon (polygon:List, width:int, height:int)\n\nnormalize polygon coordinates based on image height and width\n\ntrn_image_names = get_name(trn_img_path.ls())\n\n\nsource\n\n\ncreate_yolo_dataset\n\n create_yolo_dataset (img_path:Union[str,pathlib.Path],\n                      output_path:Union[str,pathlib.Path],\n                      json_path:Union[str,pathlib.Path])\n\nCreate yolo dataset from coco format\n\ncreate_yolo_dataset(\n    img_path=trn_img_path,\n    output_path=trn_output_path,\n    json_path=trn_json_path,\n)\n\n\n\n\n\nj\n\n\nnames = [cat['name']for cat in json_data['categories']]\nnc = len(names)\nnc\n\n1\n\n\n\nsource\n\n\ncreate_yaml\n\n create_yaml (json_path:Union[str,pathlib.Path],\n              yaml_path:Union[str,pathlib.Path],\n              train_path:Union[str,pathlib.Path],\n              val_path:Union[str,pathlib.Path],\n              test_path:Union[str,pathlib.Path,NoneType]=None)\n\nCreate a yaml with trianing and validation images path\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\njson_path\ntyping.Union[str, pathlib.Path]\n\njson path with its name\n\n\nyaml_path\ntyping.Union[str, pathlib.Path]\n\noutput path with yaml name\n\n\ntrain_path\ntyping.Union[str, pathlib.Path]\n\ntrain images path\n\n\nval_path\ntyping.Union[str, pathlib.Path]\n\nvalidation images path\n\n\ntest_path\ntyping.Union[str, pathlib.Path, NoneType]\nNone\n\n\n\nReturns\nNone\n\n\n\n\n\n\nyolo_trn_images = f'/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images'\n\n\nPath(yolo_trn_images).ls()\n\n(#1642) [Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_162_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_11_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_70_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_67_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_74_p_9.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_16_p_5.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_23_p_1.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_112_p_6.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_121_p_11.png'),Path('/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train/images/img_152_p_1.png')...]\n\n\n\ncreate_yaml(\n    json_path=trn_json_path, \n    yaml_path=f'{path}/data.yaml', \n    train_path=yolo_trn_images, \n    val_path=trn_img_path,\n    )\n\n\ntrn_json_path = str(trn_json_path)\njson_data = read_json(trn_json_path)\ntrn_img_path\n\nPath('/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images')\n\n\n\nnames = [i['name'] for i in json_data['categories']]\nnc = len(names)\nnames, nc\n\n(['object'], 1)",
    "crumbs": [
      "first find the data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "yolo_v8_segmentation",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "yolo_v8_segmentation"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "yolo_v8_segmentation",
    "section": "Install",
    "text": "Install\npip install yolo_v8_segmentation",
    "crumbs": [
      "yolo_v8_segmentation"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "yolo_v8_segmentation",
    "section": "How to use",
    "text": "How to use\n\nVisualize mask and image\n\nfrom yolo_v8_segmentation.viz_utils import *\n\n\nmsk_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks')\nimg_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/')\n\n\nidx = 2\nimage = img_path.ls()[idx]\nmsk = msk_path.ls()[idx]\n\n\nsource\n\n\noverlay_mask_border_on_image\n\n overlay_mask_border_on_image (im_path, msk_path, border_color=(0, 1, 0),\n                               border_width=1)\n\n*Overlays the border of a binary mask on a grayscale image and displays the result using matplotlib.\nArgs: image (numpy.ndarray): Grayscale image. mask (numpy.ndarray): Binary mask of the same size as the image. border_color (tuple): RGB color for the mask border in the range [0, 1]. border_width (int): Width of the border.\nReturns: None: The function displays a plot.*\n\noverlay_mask_border_on_image(im_path=image, msk_path=msk)\n\n\n\n\n\n\n\n\n\noverlay_mask(im_path=image, msk_path=msk)",
    "crumbs": [
      "yolo_v8_segmentation"
    ]
  },
  {
    "objectID": "index.html#yolo-annotation-visualization",
    "href": "index.html#yolo-annotation-visualization",
    "title": "yolo_v8_segmentation",
    "section": "Yolo annotation visualization",
    "text": "Yolo annotation visualization\n\nUpto now it is just a folder where there are some image and mask pairs. Previous method shows the masks and images\nIn case data is prepared in .txt format for training yolo, it is important to check it whether the annotations are correct or not. This function will help to visualize the annotations on the image.\n\n\nyolo_mask_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/yolo_dataset_train')\nim_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_images/')\n\n\noverlay_yolo_mask(im_path=im_path, msk_path=yolo_mask_path)\n\n\n\n\n\n\n\n\n\nin case specific image wanted to see, then one need to pass the image name to the function\n\nhere I am using im_name=None, so random image is selected\n\n\n\noverlay_yolo_mask(im_path=im_path, msk_path=yolo_mask_path, im_name=None, fill=True, alpha=0.3)\n\n\n\n\n\n\n\n\n\noverlay_yolo_mask(\n    im_path=im_path, \n    msk_path=yolo_mask_path, \n    im_name=None, \n    color='red',\n    fill=True, \n    alpha=0.3)",
    "crumbs": [
      "yolo_v8_segmentation"
    ]
  },
  {
    "objectID": "index.html#convert-label-to-yolo-format",
    "href": "index.html#convert-label-to-yolo-format",
    "title": "yolo_v8_segmentation",
    "section": "Convert label to yolo format",
    "text": "Convert label to yolo format\n\nFirst coco format json file\n\n- Normaly there are some labelling tool where you can label your images and then upload them direct in the yolo format.\n- But we are supossing that, you have some binary masks and then you want to convert them to yolo format.\n- First we will convert to coco format and then to yolo format.\n\n\n# in my case I have only one class and others are background, in case of more class, one should add name and id for the masks\n\ncategory_ids = {\n    \"object\": 1,\n}\n\n\n# where masks(in my case binary masks) are stored\ntrn_msk_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks')\n# this will be json path for the coco format\ntrn_json_path = Path(r'/home/hasan/Schreibtisch/projects/data/microscopy/patch_train_masks/train.json')\nprocess_masks(\n    mask_path=trn_msk_path, \n    json_path=trn_json_path, \n    category_ids=category_ids)\n\n\n\n\n\n\nNow coco foramt\n\ncreate_yolo_dataset(\n    img_path=trn_img_path,# train images path \n    output_path=trn_output_path, # output for each image normally some txt file\n    json_path=trn_json_path, # json path for coco format\n)\n\n\n# for yolo to run one needs to create a yaml file to tell where the data is situated\n# coco expect following format\n# train: /path/to/train/images\n# label: /path/to/train/labels\n# valid: /path/to/valid/images\n# valid_label: /path/to/valid/labels\n\ncreate_yaml(\n    json_path=trn_json_path, # coco format json path\n    yaml_path=f'{path}/data.yaml', # yaml path for saving\n    train_path=yolo_trn_images,  # where train images are stored\n    val_path=trn_img_path, # where validaiton images are stored\n    )",
    "crumbs": [
      "yolo_v8_segmentation"
    ]
  }
]