{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from fastcore.all import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Union, Callable, Optional, Dict\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first find the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code highly taken from [here](https://github.com/bnsreenu/python_for_microscopists/blob/master/332%20-%20All%20about%20image%20annotations%E2%80%8B/binary_to_coco_V3.0.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#13) [Path('/home/hasan/workspace/data/microscopy_data/training_groundtruth.tif'),Path('/home/hasan/workspace/data/microscopy_data/training.tif'),Path('/home/hasan/workspace/data/microscopy_data/mask_name.tif'),Path('/home/hasan/workspace/data/microscopy_data/testing.tif'),Path('/home/hasan/workspace/data/microscopy_data/testing_groundtruth.tif'),Path('/home/hasan/workspace/data/microscopy_data/masks'),Path('/home/hasan/workspace/data/microscopy_data/test_patch_masks'),Path('/home/hasan/workspace/data/microscopy_data/patch_images'),Path('/home/hasan/workspace/data/microscopy_data/test_patch_images'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(r'/home/hasan/workspace/data/microscopy_data/')\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1642) [Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_147_p_7.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_51_p_10.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_164_p_1.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_122_p_4.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_134_p_1.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_80_p_2.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_77_p_8.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_47_p_7.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_78_p_10.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_images/img_83_p_2.png')...],\n",
       " (#1642) [Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_147_p_7.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_51_p_10.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_164_p_1.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_122_p_4.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_134_p_1.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_80_p_2.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_77_p_8.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_47_p_7.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_78_p_10.png'),Path('/home/hasan/workspace/data/microscopy_data/patch_masks/img_83_p_2.png')...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_msk_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_images')\n",
    "trn_img_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_masks/')\n",
    "trn_output_path = Path(r'/home/hasan/workspace/data/microscopy_data/yolo_dataset_train')\n",
    "Path(trn_output_path).mkdir(parents=True, exist_ok=True)    \n",
    "\n",
    "val_msk_path = Path(r'/home/hasan/workspace/data/microscopy_data/test_patch_images/')\n",
    "val_img_path = Path(r'/home/hasan/workspace/data/microscopy_data/test_patch_masks/')\n",
    "val_output_path = Path(r'/home/hasan/workspace/data/microscopy_data/yolo_dataset_test')\n",
    "Path(val_output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trn_json_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_mask_train_coco_format.json')\n",
    "val_json_path = Path(r'/home/hasan/workspace/data/microscopy_data/patch_mask_val_coco_format.json')\n",
    "trn_msk_path.ls(), trn_img_path.ls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to create a format which can yolov8 works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. First convert coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "get_name = np.vectorize(lambda x: Path(x).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_contours(img:np.ndarray):\n",
    "    'get contours from masks'\n",
    "\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def from_contr_to_annotation(\n",
    "                            sn_cntr:list, # single contour\n",
    "                            consider_min_area:bool=True,# whether to use min_area parameter\n",
    "                            min_area:int=0,\n",
    "                            )->Tuple:\n",
    "    'Create annotation dict from  a single contour'\n",
    "    bbox = cv2.boundingRect(sn_cntr)\n",
    "    area = cv2.contourArea(sn_cntr)\n",
    "    segmentation = sn_cntr.flatten().tolist()\n",
    "    if consider_min_area:\n",
    "        if area > min_area:\n",
    "            return bbox, area, segmentation\n",
    "        return None, None, None\n",
    "    else:\n",
    "        return bbox, area, segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_mask_info(\n",
    "        msk_path, \n",
    "        min_area=0,\n",
    "        )->Tuple:\n",
    "    all_masks = msk_path.ls()\n",
    "\n",
    "    image_infos = []\n",
    "    annotations = []\n",
    "    annotation_id=0\n",
    "    for idx, msk_fn in tqdm(enumerate(all_masks),total=len(all_masks)):\n",
    "        image_id = idx +1\n",
    "        file_name = msk_fn.name\n",
    "\n",
    "        mask = cv2.imread(str(msk_fn), cv2.IMREAD_GRAYSCALE)\n",
    "        height, width = mask.shape\n",
    "\n",
    "        if file_name not in map(itemgetter('file_name'), image_infos):  \n",
    "            image_info = {\n",
    "                'id': image_id,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'file_name': file_name}\n",
    "            image_infos.append(image_info)\n",
    "        else:\n",
    "            image_info = list(filter(lambda x: x['file_name'] == file_name, image_infos))[0]\n",
    "        \n",
    "        cntrs = get_contours(mask)\n",
    "        for cntr in cntrs:\n",
    "            bbox, area, segmentation = from_contr_to_annotation(cntr, min_area=min_area)\n",
    "            if bbox:\n",
    "                annotation = {\n",
    "                    'image_id': image_id,\n",
    "                    'id': annotation_id,\n",
    "                    'category_id': 1,\n",
    "                    'iscrowd': 0,\n",
    "                    'area': area,\n",
    "                    'bbox': bbox,\n",
    "                    'segmentation': [segmentation]\n",
    "                }\n",
    "                annotations.append(annotation)\n",
    "                annotation_id +=1\n",
    "    return image_infos, annotations, annotation_id\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d28d83c82de46049e85e81b5d22bf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_infos, annotations, annotation_id=get_mask_info(trn_msk_path, min_area=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = {\n",
    "    \"object\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_masks(\n",
    "        mask_path:Union[str, Path],\n",
    "        json_path:Union[str, Path],\n",
    "        category_ids:Dict,\n",
    "        ):\n",
    "    coco_format = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"images\":[],\n",
    "        \"categories\": [{\"id\":v, \"name\":k, \"supercategory\":k } for k, v in category_ids.items()],\n",
    "        \"annotations\":[]\n",
    "\n",
    "    }\n",
    "\n",
    "    coco_format['images'], coco_format['annotations'], ann_cnt = get_mask_info(mask_path)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(coco_format, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating coco format json file for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfdc9fca2c94117aad1f51175a04d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_masks(\n",
    "    mask_path=trn_msk_path, \n",
    "    json_path=trn_json_path, \n",
    "    category_ids=category_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating coco format for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c064f8e3884caa8fef81b2ec0f8730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_masks(\n",
    "    mask_path=val_msk_path, \n",
    "    json_path=val_json_path, \n",
    "    category_ids=category_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Now convet to yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_images = trn_img_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = read_json(trn_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'categories', 'images', 'info', 'licenses'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_file_info(json_data:dict, file_name:str):\n",
    "    return list(filter(lambda x: x['file_name'] == file_name, json_data['images']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_annotations(json_data:dict, file_name:str):\n",
    "    image_id = get_file_info(json_data, file_name)['id']\n",
    "    return list(filter(lambda x: x['image_id'] == image_id, json_data['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalized_polygon(polygon:List, width:int, height:int):\n",
    "    'normalize polygon coordinates based on image height and width'\n",
    "\n",
    "    n_p = np.array(polygon).reshape(-1, 2) / np.array([image_width, image_height])\n",
    "    return n_p.flatten().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_image_names = get_name(trn_img_path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('img_147_p_7', '.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e21e0a425a4019b68681865a00892e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(trn_image_names,total=len(trn_image_names)):\n",
    "    file_info = get_file_info(json_data, i)\n",
    "    image_height = file_info['height']\n",
    "    image_width = file_info['width']\n",
    "    image_annotation = get_annotations(json_data, i)\n",
    "    if image_annotation:\n",
    "        with open(trn_output_path/f'{Path(i).stem}.txt', 'w') as f_o:\n",
    "            for ann in image_annotation:\n",
    "                current_cat = ann['category_id'] -1\n",
    "                polygon = ann['segmentation'][0]\n",
    "                norm_poly = normalized_polygon(\n",
    "                                            polygon, \n",
    "                                            width=image_width, \n",
    "                                            height=image_height)\n",
    "\n",
    "                f_o.write(f'{current_cat} {\" \".join(map(str, norm_poly))}\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_yolo_dataset(\n",
    "    img_path:Union[str, Path],\n",
    "    output_path:Union[str, Path],\n",
    "    json_path:Union[str, Path],\n",
    "    )->None:\n",
    "\n",
    "    'Create yolo dataset from coco format'\n",
    "\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_data = read_json(json_path)\n",
    "\n",
    "    # getting the names of  the images\n",
    "    image_names = get_name(img_path.ls())\n",
    "\n",
    "    for i in tqdm(image_names,total=len(image_names)):\n",
    "\n",
    "        file_info = get_file_info(json_data, i)\n",
    "        image_height = file_info['height']\n",
    "        image_width = file_info['width']\n",
    "        image_annotation = get_annotations(json_data, i)\n",
    "        # in case annotations available\n",
    "        if image_annotation:\n",
    "\n",
    "            # Creating txt file for each image\n",
    "            with open(output_path/f'{Path(i).stem}.txt', 'w') as f_o:\n",
    "                for ann in image_annotation:\n",
    "                    current_cat = ann['category_id'] -1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    norm_poly = normalized_polygon(\n",
    "                                                polygon, \n",
    "                                                width=image_width, \n",
    "                                                height=image_height)\n",
    "\n",
    "                    f_o.write(f'{current_cat} {\" \".join(map(str, norm_poly))}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd69de71c2c4fd2a6d9d4659fe6e7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_yolo_dataset(\n",
    "    img_path=val_img_path,\n",
    "    output_path=val_output_path,\n",
    "    json_path=val_json_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [cat['name']for cat in json_data['categories']]\n",
    "nc = len(names)\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_yaml(\n",
    "    json_path:Union[str, Path], # json path with its name\n",
    "    yaml_path:Union[str, Path], # output path with yaml name\n",
    "    train_path:Union[str, Path],# train images path\n",
    "    val_path:Union[str, Path], # validation images path\n",
    "    test_path:Union[str, Path, None]=None,\n",
    "    )->None:\n",
    "\n",
    "    ' Create a yaml with trianing and validation images path'\n",
    "\n",
    "\n",
    "    json_data = read_json(json_path)\n",
    "    names = [cat['name']for cat in json_data['categories']]\n",
    "\n",
    "    # Number of classes\n",
    "    nc = len(names)\n",
    "    yaml_data ={\n",
    "        'names': names,\n",
    "        'nc': nc,\n",
    "        'test':test_path if test_path else '',\n",
    "        'train':train_path,\n",
    "         'val':val_path\n",
    "\n",
    "    }\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(\n",
    "                yaml_data, \n",
    "                f, \n",
    "                default_flow_style=False\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yaml(\n",
    "    json_path=trn_json_path, \n",
    "    yaml_path=f'{path}/data.yaml', \n",
    "    train_path=trn_img_path, \n",
    "    val_path=val_img_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
